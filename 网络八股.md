## 基础

### 网络模型

* 应用层
  * HTTP FTP Telnet DNS SMTP 等
* 传输层，为应用层提供网络服务
  * TCP
  * UDP
* 网络层
  * IP
    * 负责寻址、路由
    * 超过 MTU 会分片
  * ICMP
    * `ICMP` 用于告知网络包传送过程中产生的错误以及各种控制信息。
  * ARP
    * 用于根据 IP 地址查询相应的以太网 MAC 地址。
* 网络接口层 Link Layer 链路层？
  * 在 IP 头部加上 MAC 头部

### 键入网址到网页显示的过程

#### HTTP

#### URL 解析

#### 生成请求报文

#### 域名解析 DNS

#### 传给协议栈

#### TCP 传输，封包，分包，三次握手

TCP 包头格式

* 端口号
* 序号
* 确认号
* 首部 | 六种标志 （URG ACK PSH SYN FIN RFT）| 窗口大小
* 校验和 | 紧急指针？
* 选项
* 数据

![TCP 包头格式](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/%E9%94%AE%E5%85%A5%E7%BD%91%E5%9D%80%E8%BF%87%E7%A8%8B/8.jpg)

TCP 的状态可以用 netstat 查看

```bash
netstat -nlp
// -n numerical address 数字地址
// -l listen
// -a all (listen & not listen)
// -p pid
// Recv-Q 还没被消化的 byte, Send-Q 还没发完的 byte
Proto Recv-Q Send-Q Local Address           Foreign Address         State       PID/Program name    
tcp        0      0 127.0.0.1:631           0.0.0.0:*               LISTEN      -               
```

如果 HTTP 请求消息比较长，超过了 `MSS` 的长度，这时 TCP 就需要把 HTTP 的数据拆解成一块块的数据发送，而不是一次性发送所有数据。

#### 网络层定位 IP：封装，分片，路由

![IP 层报文](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/%E9%94%AE%E5%85%A5%E7%BD%91%E5%9D%80%E8%BF%87%E7%A8%8B/17.jpg)



#### 加上 MAC 头部 

48 位dst mac 48位src mac 16位协议类型（IP, ARP）

**只有IP地址，不要MAC地址？**

1.IP地址是有限的，根本就不够用，不可能为全球每台计算机都分配一个IP地址。
2.MAC地址**全球固定而且唯一**的，有了MAC地址就能准确的找到你的计算。
3.如果IP层抢了第二层的饭碗，你就不得不考虑第二层的很多东西了，这就让IP层的实现变得十分困难。

**IP 是有限的，有规则的，可变的。MAC 是厂商决定的。**



#### 到网口，硬件传输

交换机

路由器

![网络分层模型](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/%E9%94%AE%E5%85%A5%E7%BD%91%E5%9D%80%E8%BF%87%E7%A8%8B/25.jpg)

Linux 发送网络包

把待发送的数据拷贝到 **stk_buff** 并加入到 **ring buffer** 里

传输层填充/拷贝 stk_buff。

![img](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost4@main/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E5%A4%9A%E8%B7%AF%E5%A4%8D%E7%94%A8/sk_buff.jpg)

然后**交给网络层**，在网络层里会做这些工作：**选取路由**（确认下一跳的 IP）、**填充 IP 头**、netfilter 过滤、对超过 MTU 大小的**数据包进行分片**。处理完这些工作后会**交给网络接口层**处理。

**网络接口层**会通过 **ARP 协议**获得下一跳的 **MAC 地址**，然后对 **sk_buff 填充帧头和帧尾**，接着将 sk_buff **放到网卡的发送队列**中。

会触发**「软中断」告诉网卡驱动程序**，这里有新的网络包需要发送，驱动程序会从发送队列中**读取 sk_buff，将这个 sk_buff 挂到 RingBuffer 中**，接着将 sk_buff 数据映射到网卡可访问的内存 DMA 区域，最后触发真实的发送。

**三次内存拷贝**

第一次，调用发送数据的系统调用的时候，内核会申请一个**内核态的 sk_buff** 内存，将**用户待发送的数据拷贝到 sk_buff 内存**，并将其加入到发送缓冲区。

第二次，在使用 TCP 传输协议的情况下，从传输层进入网络层的时候，每一个 sk_buff 都会被**克隆一个新的副本**出来。副本 sk_buff 会被送往网络层，等它发送完的时候就会释放掉，然后原始的 sk_buff 还保留在传输层，目的是为了实现 TCP 的可靠传输，等收到这个数据包的 ACK 时，才会释放原始的 sk_buff 。

第三次，当 IP 层**发现 sk_buff 大于 MTU 时**才需要进行。会**再申请额外的 sk_buff**，并将原来的 sk_buff 拷贝为多个小的 sk_buff。



## HTTP

### 基础

HTTP 是超文本传输协议，也就是**H**yperText **T**ransfer **P**rotocol。

#### 常见的状态码

200 204 206 成nocont partial

301 302 **304** 永久移动， Found， not modified

400 403 **404** bad request，forbidden，Not Found

500 501 502 503 bad service, not implement, bad gateway, not available

* 1 开头 提示信息，用的不多

* 2 开头 成功信息。

  * **200 成功**，一切正常。
  * 204 No Content  正常，但是响应头没有body。
  * 206 partial content 收到了一部分。

* 3 开头 重定向。资源变动，需要重新发请求。

  * **301** **Moved Permanently**	永久移动了。需要用新的 URL。
  * **302** Found  找到了，但是暂时要用其他链接。
  * **304** **Not Modified**  缓存重定向，可以直接访问缓存。
  * 301 和 302 都会在响应头里使用字段 **`Location`**，指明后续要跳转的 URL，浏览器会自动重定向新的 URL。

* 4 开头 客户端错误。请求**报文有误**。服务器无法处理

  * 400 Bad Request 报文有误。
  * **403 Forbidden** 禁止访问
  * **404 Not Found** 请求的资源不存在或者没找到。

* 5 开头 服务器错误。服务器内部发生了错误。

  * **500 Internal Server Error** 笼统的错误
  * 501 Not Implement 不支持请求
  * 502 **Bad Gateway** **服务器作为网关或代理**时返回的错误码，表示**服务器自身工作正常**，访问后端服务器发生了错误
  * 503 **service unavailable** 忙

  

![ 五大类 HTTP 状态码 ](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/HTTP/6-%E4%BA%94%E5%A4%A7%E7%B1%BBHTTP%E7%8A%B6%E6%80%81%E7%A0%81.png)

#### Http 报文

* 请求报文：请求行
  * 说明方法
  * URL
  * http 版本
* 响应报文：状态行
  * 版本
  * 状态码
  * 短语：状态码的说明

![HTTP 的消息格式](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/%E9%94%AE%E5%85%A5%E7%BD%91%E5%9D%80%E8%BF%87%E7%A8%8B/4.jpg)

#### 常见的字段

* **Host**
  * 指定服务器的域名，有了 `Host` 字段，就可以将请求发往「同一台」服务器上的不同网站。
* **content-Length**
  * 服务器返回的时候注明长度。
  * 配合回车换行解决 TCP 粘包问题。
* **connection**
  * keep-alive 长连接
  * close
* **Content-Type**
  * 编码方式
* **Cotent Encode**
  * 压缩方法



#### Http 的 keep-alive 和 tcp 的 keep alive 区别

HTTP 的 Keep-Alive 也叫 **HTTP 长连接**，该功能是**由「应用程序」实现**的，可以使得用同一个 TCP 连接来发送和接收多个 HTTP 请求/应答，减少了 HTTP 短连接带来的多次 TCP 连接建立和释放的开销。

* 用一个 tcp 连接接收多个请求。而不是收到一个关闭一次 tcp。
* 一段时间后没收到请求则由应用层发起关闭。

TCP 的 Keepalive 也叫 **TCP 保活机制**，该功能是**由「内核」实现**的，当客户端和服务端**长达一定时间没有进行数据交互时，内核为了确保该连接是否还有效，就会发送探测报文**，**来检测对方是否还在线**，然后来决定是否要关闭该连接。

* 超时**检测对方是否还在线**。

一个是看对方还有没有请求，一个是 TCP 检查对方是否还在线（连接是不是有效）。



#### GET 和 POST

get 是请求资源。

* 请求的参数放在 URL。
* 是**安全且幂等**的
* 可以缓存

post 是根据请求对资源做出处理。

* 请求的载荷放在请求报文的 body 里。
* **不安全，不幂等**
* 不能缓存

实际过程中，开发者不一定会按照 RFC 规范定义的语义来实现 GET 和 POST 方法。

get请求也可以带body，posy也可以在url上放参数。

从参数、幂等性安全性回答。



#### HTTP 缓存

强制缓存和协商缓存

速记 

强制 ：**cache control & expires**

协商：**Etag & if none match** ,  **If modified since & last modified**

先看 cache control 要不要强制使用缓存，再问 Etag ，last modified 是不是过期了，回复 304 就是可以使用缓存。

**强制缓存**：没过期就访问缓存。以下两个字段用来表示资源在客户端缓存的有效期

* cache control（优先级更高）
  * 相对时间
* expires
  * 绝对时间



**协商缓存**： 服务端告诉客户端能不能继续用缓存。

请求的响应码是 `304`  not modified 这个是告诉浏览器**可以使用本地缓存的资源**。可以基于两种头部实现。

* 第一种：请求头部中的 `If-Modified-Since` 字段与响应头部中的 `Last-Modified` 字段实现
  * If-Modified-Since
    * 资源过期，带上 last-modified 请求服务器，服务器对比 last-modified 时间。响应 200 或者 304。
  * last-modifed 告知最后修改时间
* 第二种：请求头部中的 `If-None-Match` 字段与响应头部中的 `ETag` 字段
  * 响应的 etag 唯一标识响应资源
  * 请求的 ifnonematch 资源过期时，将 ifnonematch 设置为之前收到的 etag。服务器对比有没有修改。响应200 或者 304。

第一种实现方式是**基于时间**实现的，第二种实现方式是**基于一个唯一标识实**现的，相对来说后者可以更加准确地判断文件内容是否被修改，避免由于时间篡改导致的不可靠问题。

服务器先检查 Etag 再检查 last modified

Etag 能解决 last modified 的问题。

1. 在**没有修改文件内容**情况下文件的**最后修改时间可能也会改变**，这会导致客户端认为这文件被改动了，从而重新请求；
2. 可能有些文件是在**秒级以内修改**的，`If-Modified-Since` 能检查到的**粒度是秒级**的，使用 Etag就能够保证这种需求下客户端在 1 秒内能刷新多次；（频率）
3. 有些**服务器不能精确获取文件的最后修改时间**。（精度）



**使用 Etag 协商缓存的过程**

- 当浏览器第一次请求访问服务器资源时，服务器会在返回这个资源的同时，在 Response 头部加上 ETag 唯一标识，这个唯一标识的值是根据当前请求的资源生成的；

- 当浏览器再次请求访问服务器中的该资源时，首先会先检查强制缓存是否过期：

  - 如果没有过期，则直接使用本地缓存；
  - 如果缓存过期了，会在 Request 头部加上 If-None-Match 字段，该字段的值就是 ETag 唯一标识；

- 服务器再次收到请求后，

  会根据请求中的 If-None-Match 值与当前请求的资源生成的唯一标识进行比较

  - **如果值相等，则返回 304 Not Modified，不会返回资源**；
  - 如果不相等，则返回 **200** 状态码和返回资源，并在 Response 头部加上**新的 ETag** 唯一标识；

- 如果浏览器收到 304 的请求响应状态码，则会从本地缓存中加载资源，否则更新资源。



### HTTP 各个版本

#### Http 1.1

无状态、明文、不安全。

* **长连接**
  * 一个tcp连接可以处理多个请求

* **管道网络**传输 (pipeline)
  * 可以发起多个请求
  * 服务器按序发送响应。
  * 解决了**请求的对头阻塞** *(但是没有解决响应的对头阻塞)

#### HTTPS

速记：**窃听** （混合加密），**篡改** （哈希+数字签名），**冒充**（CA对服务器的公钥用 CA 私钥做数字签名）

* 在 TCP 和 HTTP 网络层之间加入了 SSL/TLS 安全协议，使得报文能够加密传输。
* 三次握手之后，需要 TLS/SSL 握手。
* 默认端口号 443
* 服务器需要申请证书

解决了三个问题

* **窃听** : 窃听用户信息。

  * **信息加密**
  * 混合加密
    * 对称加密 + 非对称加密
    * 在通信建立前采用**非对称加密**的方式交换「会话秘钥」，后续就不再使用非对称加密。
    * 在通信过程中全部使用**对称加密**的「会话秘钥」的方式加密明文数据。

* **篡改** ：植入广告。

  * 校验
  * 摘要算法
  * 计算一个哈希值.
    * 为了防止内容和哈希值一起被替换使用**数字签名**
      * 把哈希值用私钥加密

* **冒充** ：冒充假网站。

  * 证书
  * 公钥放入数字证书
  * 私钥加密，公钥解密。
  * 向 CA 注册 避免公钥被冒充
  * 证书 = 公钥 + CA对公钥的签名

  

- **公钥加密，私钥解密**。这个目的是为了**保证内容传输的安全**，因为被公钥加密的内容，其他人是无法解密的，只有持有私钥的人，才能解密出实际的内容；
- **私钥加密，公钥解密**。这个目的是为了**保证消息不会被冒充**，因为私钥是不可泄露的，如果公钥能正常解密出私钥加密的内容，就能证明这个消息是来源于持有私钥身份的人发送的。

#### RSA 四次握手 (ACK 没算在握手里)

TODO

**第一次握手 Client hello**

* 发送公钥加密的 **随机数**
* 以及 tls 版本,支持的密码套件



**第二次握手 Server hello**

* 发送**随机数**
* 选择密码套件和版本

这两次握手是为了协商 「**密钥交换算法 + 签名算法 + 对称加密算法 + 摘要算法**」

然后 server 发 **Server Certificate**

* 证明自己的身份.包含数字证书

最后 server 发 **Server Hello Done**



**第三次握手 Client key exchange**

客户端生成新的随机数 **(pre-master)** 用服务器**公钥加密**发给服务器

至此，客户端和服务端双方都共享了三个随机数，分别是 **Client Random、Server Random、pre-master**。

双方根据已经得到的三个随机数，生成**会话密钥（Master Secret）**，它是**对称密钥**，用于对后续的 HTTP 请求/响应的数据加解密。

然后发 **Change Cipher Spec** 告诉服务端以后加密通信.

客户端检验有没有篡改,发送 FInished



**TLS 第四次握手**

服务器也是同样的操作，发「**Change Cipher Spec**」和「**Encrypted Handshake Message**」消息，如果双方都验证加密和解密没问题，那么握手正式完成。

服务端发送确认.



#### HTTP1.1 优化

* **缓存**
* 减少**重定向次数**
  * 代理服务器把重定向请求缓存到本地
* **合并请求** 解决头部冗余
* **延迟请求**，按需发送请求
* 压缩







#### HTTP2

速记：**头部压缩**、**二进制**、**流技术**、**客户端主动推送**。但是 TCP 仍然会对头阻塞导致流不是完全并发的。

HTTP1的问题

* http头部大
* 并发小
* 不支持服务器推送
* 队头阻塞

优化

* 头部压缩
* 二进制帧
* **并发传输**
  * **stream 技术**
  * 每个帧都有 stream ID 不同的 stream 可以并发
  * ![image-20240105143224839](https://cdn.xiaolincoding.com//picgo/image-20240105143224839.png)
  * 一个 tcp 连接有多个 stream 一个 stream 有多个 message 一个message 有多个帧, 一个帧由多个 tcp 包发出
  * **客户端发起的请求，必须使用的是奇数号 Stream**，**服务器主动的推送，使用的是偶数号 Stream。**
* 服务器主动推送
  * 通过偶数号的 stream



#### 队头阻塞

HTTP/2 多个请求是跑在**一个 TCP 连接中**的，那么当 TCP 丢包时，整个 TCP 都要等待重传，那么就会阻塞该 TCP 连接中的所有请求。

比如下图中，Stream 2 有一个 TCP 报文丢失了，那么即使收到了 Stream 3 和 Stream 4 的 TCP 报文，应用层也是无法读取读取的，相当于阻塞了 Stream 3 和 Stream 4 请求。

也就是说,stream 之间并不是完全并发的.

![image-20240105143355912](https://cdn.xiaolincoding.com//picgo/image-20240105143355912.png)





#### QUIC

速记：QUIC 基于 UDP，也有连接管理、拥塞窗口、流量控制，并且可靠。解决了**队头阻塞**，并且连接更快，配合 TLS 1.3 可以**一次握手**建立连接，并且可以**连接迁移**。



HTTP/3 不仅仅只是简单将传输协议替换成了 UDP，还基于 UDP 协议在「应用层」实现了 **QUIC 协议**，它具有类似 TCP 的**连接管理**、**拥塞窗口**、**流量控制**的网络特性，相当于将不可靠传输的 UDP 协议变成“可靠”的了，所以不用担心数据包丢失的问题。

QUIC 协议的优点有很多，这里举例几个，比如：

- **无队头阻塞**；

- **更快的连接建立**；
  - QUIC 只需要一次握手就可以建立连接 （确认**连接 ID**）

  -  QUIC 内部包含了 TLS，它在自己的帧会携带 TLS 里的“记录”，再加上 QUIC 使用的是 TLS 1.3，因此**仅需 1 个 RTT 就可以「同时」完成建立连接与密钥协商**，甚至在第二次连接的时候，应用数据包可以和 QUIC 握手信息（连接信息 + TLS 信息）一起发送，达到 0-RTT 的效果。

- **连接迁移**；
  - 基于**连接 ID**


QUIC 连接上的多个 Stream 之间并没有依赖，都是独立的，某个流发生丢包了，只会影响该流，其他流不受影响。



QUIC 实现原理简单说明：

4.29 连接快, 通过连接 id 标识连接, 可以迁移. 携带流 id 和流偏移, 没有队头阻塞问题. 传输控制是在应用层实现的. 

1. 更快的连接：0-rtt 握手。第一次需要 1-rtt ，非首次连接可以带上 early data。客户端可以保存服务端的公钥。
2. 自定义的拥塞控制
   1. 每个包有新的编号，携带 ack 时延信息用于计算 RTT。
   2. 在应用层上实现传输控制。
3. 无队头阻塞。
   1. 使用 Packet Number 代替了 TCP 的 Sequence Number，并且每个 Packet Number 都严格递增
   2. 支持**乱序确认**。
   3. 携带 Stream ID 和 Stream offset
4. 用 connection id 标识连接





#### **HTTP 和 RPC 的区别**

服务发现，不是很关键。

底层连接方式，RPC 有连接池，也不是很关键。

**传输的内容**和**编码方式**

* http 传 header 和 body 
  * header 的字段一般不需要
  * body 用 json 序列化结构体，不是很简洁
* RPC 可以**高度定制化**

  * 可以用其他序列化协议：**protobuf 更小更快**
  * 不用考虑服务器**响应码**
  * 不用管**浏览器、缓存**什么的

  - RPC 其实比 HTTP 出现的要早，且比目前主流的 HTTP/1.1 **性能**要更好，所以大部分公司内部都还在使用 RPC。
  - **HTTP/2.0** 在 **HTTP/1.1** 的基础上做了优化，性能可能比很多 RPC 协议都要好，但由于是这几年才出来的，所以也不太可能取代掉 RPC。







## TCP 篇



### TCP 基础

TCP 头有什么?

* 16 位源端口 目的端口
* 首部长度
* 标志位
  * URG
  * PSH
  * ACK
  * SYN
  * FIN
  * RST 异常
* 16 位窗口大小
* 16 位checksum
* 16 位紧急指针
* 选项

![TCP 头格式](https://cdn.xiaolincoding.com//mysql/other/format,png-20230309230534096.png)



TCP 的三个特点

* 可靠: 应对网络环境. 
  * 完整
  * 有序
  * 不丢失
  * 不重复
* 面向连接
  * 一对一连接
* 字节流
  * 不区分边界



四元组 源 IP 目的 IP 源端口 目的端口

所以一个监听了一个端口的服务器最多可以连接 2^32 * 2^16 个 TCP 连接.

但是实际上会受到限制

* 文件描述符大小.每一个 TCP 占用一个文件描述符
* 内存限制



**TCP 和 UDP 区别：**

*1. 连接*

- TCP 是面向连接的传输层协议，传输数据前先要建立连接。
- UDP 是不需要连接，即刻传输数据。

*2. 服务对象*

- TCP 是一对一的两点服务，即一条连接只有两个端点。
- UDP 支持一对一、**一对多**、**多对多**的交互通信

*3. 可靠性*

- TCP 是**可靠**交付数据的，数据可以**无差错、不丢失、不重复、按序到达**。
- UDP 是尽最大努力交付，不保证可靠交付数据。但是我们可以基于 UDP 传输协议实现一个可靠的传输协议，比如 QUIC 协议，具体可以参见这篇文章：[如何基于 UDP 协议实现可靠传输？(opens new window)](https://xiaolincoding.com/network/3_tcp/quic.html)

*4. 拥塞控制、流量控制*

- TCP 有拥塞控制和流量控制机制，保证数据传输的安全性。
- UDP 则没有，即使网络非常拥堵了，也不会影响 UDP 的发送速率。

*5. **首部开销***

- TCP 首部长度较长，会有一定的开销，首部在没有使用「选项」字段时是 `20` 个字节，如果使用了「选项」字段则会变长的。
- UDP 首部只有 8 个字节，并且是固定不变的，开销较小。

*6. 传输方式*

- TCP 是流式传输，没有边界，但保证顺序和可靠。
- UDP 是一个包一个包的发送，是有边界的，但可能会丢包和乱序。

*7. **分片不同***

- TCP 的数据大小如果大于 MSS 大小，则会在传输层进行分片，目标主机收到后，也同样在传输层组装 TCP 数据包，如果中途丢失了一个分片，只需要传输丢失的这个分片。
- UDP 的数据大小如果大于 MTU 大小，则会在 IP 层进行分片，目标主机收到后，在 IP 层组装完数据，接着再传给传输层。

### TCP 三次握手

seq = 前者的 ack, ack = 下一个想要的包

客户端 SYN seq = RAND1 

服务端 SYN + ACK seq = RAND2, ack = RAND1 + 1

客户端 ACK seq = rand1+1 ack = rand2+1

**第三次握手可以携带数据**



原因 (**同步信息, 防止浪费, 防止历史连接**)

* 为了保证能相互沟通上. 客户端询问-服务端回答 服务端询问,客户端回答 中间的合并了
* 为了交换信息 双方的**初始序列号**, **窗口大小**, **MSS**
  * MSS 是为了保证不会被 IP 分片.
* 阻止历史连接 (也就是以前发送的 SYN 报文).
  * 考虑这种情况: 客户端发了 SYN 然后宕机了, 恢复后重发新的 SYN, 服务端收到了旧的 SYN 发了 ACK
  * 如果两次握手, 服务端就建立了一个无效的历史连接
* 另外, 可以避免浪费
  * 客户端如果收到第二次握手就建立连接, 可能他的 ACK 客户端收不到.
  * 客户端会重发 SYN, 服务端每次收到 SYN 都建一个连接, 很浪费

TCP 建立连接时，通过三次握手**能防止历史连接的建立，能减少双方不必要的资源开销，能帮助双方同步初始化序列号**。



#### 握手丢失的处理

第一次丢了: 客户端重发 SYN

第二次丢了, 客户端以为自己没发过去, 重发 SYN, 服务端没收到第三次握手, 以为自己没发过去 重发 SYN + ACK

第三次丢了, 服务端以为自己没发过去 重发 SYN + ACK



#### SYN FLOOD 攻击

攻击者狂发 SYN, 占满接收者的半连接队列. 

办法: 

* **首包丢弃** 看对方是不是有诚意
* 开启 **SYN COOKIE**
  * 参数 net.ipv4.tcp_syncookies 可以设置关闭, 满的时候开启, 或者一直开启
    * 0 值，表示关闭该功能；
    * 1 值，表示**仅当 SYN 半连接队列放不下时，再启用它**；
    * 2 值，表示无条件开启功能；
* 调大网路连接参数
  * netdev_max_backlog 硬件缓冲连接数
  * max_syn_backlog 全连接最大连接数
  * somaxconn **最大监听队列长度**

**原理**

在 TCP 三次握手的时候，Linux 内核会维护两个队列，分别是：

- **半连接队列**，也称 **SYN 队列**；
- **全连接队列**，也称 **accept 队列**；

看这篇文章

[从Linux源码看Socket(TCP)的listen及连接队列 - 无毁的湖光-Al - 博客园 (cnblogs.com)](https://www.cnblogs.com/alchemystar/p/13845081.html)



#### TCP 调优命令

TCP 连接参数涉及到: socket 个数有关的 fd 数量, 半连接队列长度, 全连接队列长度, 硬件缓冲的队列长度

更改文件描述符, 监听队列长度, 全连接队列长度, 硬件缓冲队列长度

* **ulimit -n**
  * 设置用户进程打开文件描述符的最大值
    * ulimit：用于限制用户级别的文件描述符数，是用户级别的资源限制。
    * file-max：用于限制整个系统级别的文件描述符数，是系统级别的资源限制。
      * /proc/sys/fs/file-max
* **somaxconn** Socket
  * 控制服务器**监听队列长度**的参数, 也称为**最大连接数参数**, 决定服务器能够接受的最大连接数的上限
  * 临时更改 **sysctl -w** net.core.somaxconn=<new_value>
  * 永久更改 修改`/etc/sysctl.conf` net.core.somaxconn = <new_value>
  * somaxconn 是一个内核参数，用于控制服务器的**监听队列长度**。当一个服务端程序使用 **listen()** 函数监听某个端口时，内核会为该监听套接字创建一个队列，用于暂时存放客户端发起的连接请求，而尚未被服务器 accept() 函数接受处理的连接。**somaxconn 参数决定了这个监听队列的最大长度**，也即可以同时排队等待处理的连接请求数的上限。
  
* n**etdev_max_backlog**
  * net device max backlog 硬件可以处理的最大连接数. 接受速度快于处理速度时, 连接放在这个队列里
* **tcp_max_syn_backlog**
  * SYN 队列的长度, 默认为 1024

// Listen 里的 backlog 参数是指定全连接队列的长度捏.





### 四次挥手

主动关闭方 					被动关闭方

estabished ------------------- estabished

finwait1 FIN1 -------FIN------> estabished

finwait1			<-----ACK------ Closed_wait		(等待**调用 close 函数** 发送 FIN)   就是再被关闭方的接收缓冲区里**塞一个结束符**.

finwait1			<-----FIN------ LAST_ACK			(等待主动关闭方最后一次 ACK)

==TImewait==		-------ACK-------> LAST_ACK

等待2MSL							     Close

close



更详细的描述

众所周知，由于 socket 是**全双工**的工作模式，一个 socket 的关闭，是需要四次握手来完成的：

1. 主动关闭连接的一方，**调用 close()**；协议层**发送 FIN 包**;
2. 被动关闭的一方收到 FIN 包后，协议层**回复 ACK**；然后被动关闭的一方，**进入 CLOSE_WAIT 状态**，主动关闭的一方等待对方关闭，则进入 **FIN_WAIT_2** 状态；此时，主动关闭的一方等待被动关闭一方的应用程序，调用 close 操作;
3. 被动关闭的一方在完成**所有数据发送后**，**调用 close() 操作**；此时，协议层**发送 FIN 包**给主动关闭的一方，等待对方的 ACK，被动关闭的一方进入 **LAST_ACK** 状态；
4. 主动关闭的一方收到 FIN 包，协议层**回复 ACK**；此时，主动关闭连接的一方，**进入 TIME_WAIT 状态**；而**被动关闭的一方，进入 CLOSED 状态;**
5. **等待 2MSL 时间**，主动关闭的一方，结束 TIME_WAIT，**进入 CLOSED** 状态;





主动关闭的一方会有 time wait 状态

* TIME_WAIT 会默认等待 2MSL 时间后，才最终进入 CLOSED 状态；

被动关闭的一方有一个 **close wait** 状态

* 因为**协议层在等待上层的应用程序**，**主动调用 close** 操作后才主动关闭这条连接;
* 取决于
  * 应用程序有没有正常调用?
  * CPU 是不是很忙?
  * 程序在睡眠?

==**ACK 报文是不会重传的**==

==调用 close 后发送 FIN 报文==

#### 挥手丢失的处理

第一次挥手丢失: 关闭方再发 FIN

第二次挥手丢失: 关闭方再发 FIN

第三次挥手丢失 被关方再发 FIN

第四次挥手丢失: 被关闭方重发 FIN 关闭方每次收到 FIN 都会重置 2MSL 的计时器





#### 为什么需要 time_wait 状态

* 保证被关闭的一方能收到自己的最后一个 ack, 并正确关闭连接

* **把当前连接延迟的包都丢掉**, 防止接收到历史连接数据
  * 如果在这 2MSL 里建立了新的相同四元组连接, 有可能会收到上一次连接延迟的数据包. 如果刚好在自己的接收窗口里面, 就会收到错误的数据包



#### Timewait 过多的危害

* 占用端口号
  * **针对客户端**而言, 端口号是有限的
  * 服务端 time_wait 过多不会有端口号问题

* 占用系统资源 这个sokcet ,**fd** , **内存** **CPU** **线程**都不能回收
  * 主要针对**服务端**



#### 优化 time_wait

参数上, 设置客户端的time_wait复用, 开启时间戳识别历史包. 

策略上, 尽量让对方关闭连接, 尽量用长连接. 

1. 打开 **time_wait reuse** 和 **tcp timestamps**
   1. ==tcp_tw_reuse== 复用处于 TIME_WAIT 的 socket 为新的连接所用
   2. 只能**客户端**使用
   3. 需要开启时间戳, 重复的包会以为时间戳被丢弃掉 (会在选项里加入时间戳)
2. ==tcp_max_tw_buckets==
   1. 系统中处于 TIME_WAIT 的连接一旦超过这个值时，系统就会将后面的 TIME_WAIT 连接状态重置
   2. 调小这个值?
3. 对于服务端而言, 尽量让客户端关闭连接. 
4. 使用长连接



#### 服务端为什么会大量 time_wait ? 

也就是为什么服务端会大量主动关闭连接? 

* 没有用长连接
  * **排查下是否客户端和服务端都开启了 HTTP Keep-Alive**
* 或者长连接超时了
  * 
* 或者长连接请求达到了上限





#### 服务器出现大量 CLOSE_WAIT 状态的原因有哪些？

close wait 是被关闭方的状态. 发了 ack 后, 等待应用层调用 close 然后发 FIN

服务端大量 close_wait 说明服务端没有正常调用 close.